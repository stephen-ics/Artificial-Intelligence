{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Student_UnderstandingSiri_Section1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephen-ics/Artificial-Intelligence/blob/main/Student_UnderstandingSiri_Section1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJOo77sBWKt8"
      },
      "source": [
        "# Classifying Voice Commands\n",
        "\n",
        "How does Siri know what to do when you ask her a question or tell her a command?\n",
        "\n",
        "<img src=\"https://www.cheatsheet.com/wp-content/uploads/2016/01/Siri-in-iOS-9-640x305.png\" width=400>\n",
        "\n",
        "Obviously Siri can't predict every possible sentence someone might say to her - there's infinite possibilities! So there's definitely no way to hardcode or memorize every answer she might need.\n",
        "\n",
        "Instead, these systems have to use **Natural Language Processing** (NLP) algorithms.\n",
        "\n",
        "For voice commands, Siri needs to be able to figure out *what* the speaker wants, and then *how* to accomplish that request. <img src=\"https://images.emojiterra.com/google/android-10/512px/1f914.png\" width=20>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti3qkbz7MIIt"
      },
      "source": [
        "Throughout this project we will be analyzing verbal commands to help Siri figure out what her correct response and action should be by: \n",
        "\n",
        "a) predicting the *intent* of the speaker\n",
        "\n",
        "and\n",
        "\n",
        "b) extracting interesting named entities within the command.\n",
        "\n",
        "Part (b) is known as **Named Entity Recognition** (NER), which locates and classifies entities in text into pre-defined categories such as person names, organizations, and locations.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2594/1*rq7FCkcq4sqUY9IgfsPEOg.png\" width=\"500\">\n",
        "\n",
        "Part (a) is a sentence-level classification task, and part (b) - or NER - is a token-level classification task, which in turn will help us with the overall sentence-level task of predicting what the speaker wants!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr5S4rtvNhj3"
      },
      "source": [
        "## Example\n",
        "Here is an example of the format of the final predictions that we will produce:\n",
        "\n",
        "The command \"Book a table for two at Le Ritz for Friday night\" becomes \n",
        "\n",
        "```\n",
        "{\n",
        "    'intent': 'BookRestaurant',\n",
        "    'slots': {\n",
        "        'party_size_number': 'two',\n",
        "        'restaurant_name': 'Le Ritz',\n",
        "        'timeRange': 'Friday night'\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "As you can see, knowing the fact that 'Le Ritz' is a restaurant name, 'two' refers to a party size, and 'Friday night' means a time range would definitely help Siri realize that this speaker wants to book a restaurant reservation! <img src=\"https://s3.amazonaws.com/pix.iemoji.com/images/emoji/apple/ios-12/256/face-savouring-delicious-food.png\" width=20>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlE9nndIa-4-"
      },
      "source": [
        "In this notebook we'll be:\n",
        "*   Exploring the Dataset for the Understanding SIRI Project\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhVfDIW5WfwC"
      },
      "source": [
        "## Data\n",
        "\n",
        "We are using a voice command dataset collected, annotated, and published by a French startup SNIPS.ai (which was [bought](https://investors.sonos.com/news-and-events/investor-news/latest-news/2019/Sonos-Announces-Acquisition-of-Snips/default.aspx) last November by Audio device manufacturer Sonos).\n",
        "\n",
        "We will use a preprocessed version of this dataset with token-level BIO tagging, so it is closer to the representation that our model will predict. This variant of the SNIPS dataset was prepared by [Su Zhu](https://github.com/sz128)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGhaZfpgWjRH",
        "cellView": "form"
      },
      "source": [
        "#@title Run this code to get started\n",
        "%tensorflow_version 2.x\n",
        "%pip install -q transformers\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/train'\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/valid'\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/test'\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/vocab.intent'\n",
        "!wget -q --show-progress 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Siri%20(Bert)%20Voice%20Commands/vocab.slot'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_kdsF4HWqH2"
      },
      "source": [
        "Great! We now have data downloaded into **five files** called \"train\", \"valid\", \"test\", \"vocab.intent\", and \"vocab.slot\".\n",
        "\n",
        "Let's explore what these files contain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTchalghSuz4"
      },
      "source": [
        "Let's look at 'vocab.intent' to see what **intentions** Siri can comprehend:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYZNfLgqWjsS"
      },
      "source": [
        "# Prints vocab.intent\n",
        "intent_lines = Path(\"vocab.intent\").read_text().strip().splitlines()\n",
        "for line in intent_lines:\n",
        "  print(line)\n",
        "print(\"\\nThere are {} possible classes for the sentence level prediction task.\".format(len(intent_lines)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PDHTzqvSPXj"
      },
      "source": [
        "**Discuss**:\n",
        "\n",
        "This is clearly a toy dataset because there are only 7 things that Siri could correctly predict as the intention of a user's command. What other intent classes would be interesting and necessary for Siri to know?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9st-UnaodZQ"
      },
      "source": [
        "<img src=\"https://ift.tt/1Gkj0zA\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao2NgHguS2ET"
      },
      "source": [
        "Now let's look at 'vocab.slot' to see what kinds of **named entities** Siri has in its vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl7eIr-_Wuk8"
      },
      "source": [
        "# Prints vocab.slot\n",
        "slot_lines = Path(\"vocab.slot\").read_text().strip().splitlines()\n",
        "for line in slot_lines:\n",
        "  print(line)\n",
        "print(\"\\nThere are {} possible classes for the word level prediction task.\".format(len(slot_lines)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZagHs0RWbsQ"
      },
      "source": [
        "### **BIO Tagging**\n",
        "\n",
        "This is a common format for tagging tokens in a NER task.\n",
        "\n",
        "B = beginning\n",
        "I = inside\n",
        "O = outside\n",
        "\n",
        "The B- prefix before a tag indicates that the tag is the *beginning* of a chunk, and an I- prefix before a tag indicates that the tag is *inside* a chunk. An O tag indicates that a token belongs to *no chunk*.\n",
        "\n",
        "Using our previous example with the command \"Book a table for two at Le Ritz for Friday night\", we get the following BIO tags:\n",
        "\n",
        "```\n",
        "      Book : O\n",
        "         a : O\n",
        "     table : O\n",
        "       for : O\n",
        "       two : B-party_size_number\n",
        "        at : O\n",
        "        Le : B-restaurant_name\n",
        "         R : I-restaurant_name\n",
        "     ##itz : I-restaurant_name\n",
        "       for : O\n",
        "    Friday : B-timeRange\n",
        "     night : I-timeRange\n",
        "         ! : O\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs9gBcTmeJmN"
      },
      "source": [
        "**Discuss**: \n",
        "\n",
        "Why is BIO tagging used, and what are some potential issues with the scheme?\n",
        "\n",
        "Also, what do you think the distinction between the \"B-\" and \"I-\" prefixes is useful for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sYd4qA-WxYS"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "\n",
        "Read in the training data stored in the \"train\" file (Hint: Look at how we read in both vocab files above into ``intent_lines`` and ``slot_lines``).\n",
        "\n",
        "Then examine just the first 3 lines of train_lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plPqp9MbWxq1"
      },
      "source": [
        "# Store all the training data in train_lines, and print only the first 3 lines of train_lines.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rnOo3x4XPVX"
      },
      "source": [
        "**Format of the train data**:\n",
        "\n",
        "\n",
        "\n",
        "*   The overall intent label for the voice command is at the end of the sequence, after the \"<=>\" separator.\n",
        "*   Each word is annotated with a word-level token (BIO label), after the \":\" separator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58-Y6JOdXSdP"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Now let's parse a line of training data into a [JSON](https://en.wikipedia.org/wiki/JSON) format to get the intent, length of the command, word-level BIO tags, and the command by itself. \n",
        "\n",
        "\n",
        "1) Finish the return statement of the function ``parse_line``.\n",
        "\n",
        "2) Then test it on the first line of training data.\n",
        "(Hint: The  training data should be stored in train_lines from Exercise 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAYS9oZMXPqw"
      },
      "source": [
        "# Parses a single line of training data into a JSON representation.\n",
        "def parse_line(line):\n",
        "    data, intent_label = line.split(\" <=> \")\n",
        "    items = data.split()\n",
        "    words = [item.rsplit(\":\", 1)[0]for item in items]\n",
        "    word_labels = [item.rsplit(\":\", 1)[1]for item in items]\n",
        "    return {\n",
        "        \"intent_label\": ### YOUR CODE HERE ###, \n",
        "        \"words\": \" \".join(words),\n",
        "        \"word_labels\": ### YOUR CODE HERE ###,\n",
        "        \"length\": ### YOUR CODE HERE ###,\n",
        "    }\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HtulttRZGMg"
      },
      "source": [
        "**Discuss**:\n",
        "1. How many words are in the first sequence of the training data?\n",
        "2. How many unique BIO tags are there in the first sequence of the training data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI8tLOmCZJ4m"
      },
      "source": [
        "### Training Data Analysis\n",
        "\n",
        "Now  let's use the ``parse_line`` function we completed to parse *all* the lines of the training data and store the results in a pandas DataFrame <img src=\"https://images.emojiterra.com/google/android-10/share/1f43c.jpg\" width=40>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiBxHJzZZlcQ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "parsed_train = [parse_line(line) for line in train_lines]\n",
        "df_train = pd.DataFrame([p for p in parsed_train if p is not None])\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSRyhfaNZnzS"
      },
      "source": [
        "Here is the same training data, but grouped by the sentence-level labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SZ411OyZoLn"
      },
      "source": [
        "# Shows the number of sentences that belong to each class of the intent labels.\n",
        "df_train.groupby(\"intent_label\").count()[['words']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awR5GChgZr64"
      },
      "source": [
        "Nice! We can see that there is a pretty even number of training examples that belong to each of the 7 sentence-level classes.\n",
        "\n",
        "Let's take a look at the spread of training examples according to sequence lengths now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6vc-zKuZsNz"
      },
      "source": [
        "df_train.hist(\"length\", bins=30)\n",
        "plt.title(\"Sequence Length Histogram\")\n",
        "plt.xlabel(\"Number of words per sequence\")\n",
        "plt.ylabel(\"Count of sequences\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqH4WI9_Zv2o"
      },
      "source": [
        "# Text representation of the histogram of sequence lengths.\n",
        "count, division = np.histogram(df_train['length'], bins=30)\n",
        "\n",
        "for i in range(len(count)):\n",
        "  print(\"There are {} sequences that have between {} and {} number of words.\".format(count[i], round(division[i],3), round(division[i+1],3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJabz-VxZyuV"
      },
      "source": [
        "What are the average and maximum sequence lengths within the training dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zT6t_uPZ01E"
      },
      "source": [
        "avg_len = round(df_train['length'].mean(), 3)\n",
        "print(\"Average sequence length: {} words per sequence\".format(avg_len))\n",
        "\n",
        "max_len = max(df_train['length'])\n",
        "print(\"Maximum sequence length: {} words per sequence\".format(max_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQAKOMF6Z5S1"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Let's create pandas DataFrames for the validation & test sets too.\n",
        "\n",
        "Read in the validation and test data stored in the \"valid\" and \"test\" files (Hint: Look at the initialization of train_lines in Exercise 1).\n",
        "\n",
        "Then create two DataFrames (Hint: Look at how df_train is initialized in the first cell under Training Data Analysis)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opdHTfrVZ5rI"
      },
      "source": [
        "# Read in the lines from 'valid' & 'test' and create \n",
        "# corresponding DataFrames called df_valid and df_test.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaHNo4_waCzu"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "How many total examples are in each of the train, validation, and test sets?\n",
        "\n",
        "What is the percentage breakdown of the total dataset across the train, val, and test sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKv2RcT_aDNz"
      },
      "source": [
        "# Print how many datapoints are in each of the train, validation, & test Dataframes.\n",
        "# Also print the percentage of the total for each set.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDFFJXdxbofm"
      },
      "source": [
        "Remember that we do not normally perform analysis on the validation and test sets, because the models we train should not be able to cheat and use information outside of the training set.\n",
        "\n",
        "But out of curiosity, how many sequences of each intent label class are there in each of the validation and training sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m70o7kpJbo1S"
      },
      "source": [
        "df_valid.groupby(\"intent_label\").count()[['words']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QObmMJ5nbr88"
      },
      "source": [
        "df_test.groupby(\"intent_label\").count()[['words']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbINHnumbt1r"
      },
      "source": [
        "Cool, we can see that there is an exactly even spread among the 7 sentence-level classes for both the validation and testing sets. <img src=\"data:image/png;base64,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\" width=25>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii0mkaiPcD2a"
      },
      "source": [
        "**Discuss**:\n",
        "\n",
        "What other information or statistics would be useful in the preliminary data analysis stage before running any models on this data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVG-rNx96uyq"
      },
      "source": [
        "## (Optional): Recurrent Neural Networks\n",
        "\n",
        "Now that we have a better understanding of how our data is laid out, we can go ahead and try to start and working with it.\n",
        "\n",
        "Review [these slides](https://docs.google.com/presentation/d/1ykLNZNkql0SDqqDiNLKJVspUFhVLKB_7x-uB7sSlbNI/edit?usp=sharing) to learn more about Recurrent Neural Networks.\n",
        "\n",
        "<img src=\"https://i.imgur.com/Eo8orJ0.png\" width = 700>\n",
        "\n",
        "\n",
        "**Discussion Question:**\n",
        "How might you try to incorporate any of the models in the slides above to help us with our task?"
      ]
    }
  ]
}